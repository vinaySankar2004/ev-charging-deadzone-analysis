{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Set display options for better viewing in Jupyter\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 20)\n",
    "pd.set_option('display.width', 1000)"
   ],
   "id": "d0dcbeea3a76ef4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T01:05:37.146421Z",
     "start_time": "2025-04-21T01:05:36.796745Z"
    }
   },
   "cell_type": "code",
   "source": [
    "alarms_df = pd.read_csv('./given_data/datasets/Alarms.csv')\n",
    "anomalies_df = pd.read_csv('./given_data/datasets/Anomalies.csv')\n",
    "sessions_df = pd.read_csv('./given_data/datasets/Sessions.csv')\n",
    "stations_df = pd.read_csv('./given_data/datasets/Stations.csv')"
   ],
   "id": "f5cf6e2928e61df2",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T01:14:52.268098Z",
     "start_time": "2025-04-21T01:14:52.239939Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Remove columns with all null values\n",
    "columns_to_drop = ['timezone_offset', 'status', 'time_stamp', 'mode']\n",
    "stations_df_clean = stations_df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Verify the results\n",
    "print(f\"Original Stations shape: {stations_df.shape}\")\n",
    "print(f\"Cleaned Stations shape: {stations_df_clean.shape}\")\n",
    "\n",
    "# Display the cleaned dataframe columns\n",
    "print(\"\\nCleaned Stations columns:\")\n",
    "print(stations_df_clean.columns.tolist())\n",
    "\n",
    "stations_df = stations_df_clean\n",
    "\n",
    "# Basic info on the cleaned dataframe\n",
    "print(\"\\nCleaned Stations info:\")\n",
    "print(stations_df.info())"
   ],
   "id": "430118abc8a14fd9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Stations shape: (38, 23)\n",
      "Cleaned Stations shape: (38, 19)\n",
      "\n",
      "Cleaned Stations columns:\n",
      "['station_id', 'org_id', 'station_group', 'model', 'activation_dt', 'address', 'manufacturer', 'station_name', 'description', 'port_no', 'reservable', 'level', 'connector', 'voltage', 'current', 'power', 'estimated_cost', 'location_lat', 'location_long']\n",
      "\n",
      "Cleaned Stations info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 38 entries, 0 to 37\n",
      "Data columns (total 19 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   station_id      38 non-null     object \n",
      " 1   org_id          38 non-null     object \n",
      " 2   station_group   38 non-null     object \n",
      " 3   model           38 non-null     object \n",
      " 4   activation_dt   38 non-null     object \n",
      " 5   address         38 non-null     object \n",
      " 6   manufacturer    38 non-null     object \n",
      " 7   station_name    38 non-null     object \n",
      " 8   description     38 non-null     object \n",
      " 9   port_no         38 non-null     int64  \n",
      " 10  reservable      38 non-null     int64  \n",
      " 11  level           38 non-null     object \n",
      " 12  connector       38 non-null     object \n",
      " 13  voltage         38 non-null     int64  \n",
      " 14  current         38 non-null     int64  \n",
      " 15  power           38 non-null     float64\n",
      " 16  estimated_cost  38 non-null     float64\n",
      " 17  location_lat    38 non-null     float64\n",
      " 18  location_long   38 non-null     float64\n",
      "dtypes: float64(4), int64(4), object(11)\n",
      "memory usage: 5.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T01:21:27.656051Z",
     "start_time": "2025-04-21T01:21:27.648730Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check for duplicate station_ids\n",
    "station_id_duplicates = stations_df['station_id'].duplicated().sum()\n",
    "if station_id_duplicates == 0:\n",
    "    print(\"PASSED: All station_ids are unique in stations_df\")\n",
    "else:\n",
    "    print(f\"WARNING: Found {station_id_duplicates} duplicate station_ids\")"
   ],
   "id": "d032c52972957127",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Found 19 duplicate station_ids\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T01:21:33.617977Z",
     "start_time": "2025-04-21T01:21:33.597192Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check if all station_ids in sessions_df exist in stations_df\n",
    "station_ids_in_stations = set(stations_df['station_id'])\n",
    "station_ids_in_sessions = set(sessions_df['station_id'])\n",
    "orphaned_station_ids = station_ids_in_sessions - station_ids_in_stations\n",
    "\n",
    "if len(orphaned_station_ids) == 0:\n",
    "    print(\"PASSED: All station_ids in sessions_df exist in stations_df\")\n",
    "else:\n",
    "    print(f\"WARNING: Found {len(orphaned_station_ids)} station_ids in sessions_df that don't exist in stations_df\")\n",
    "    print(list(orphaned_station_ids)[:5])  # Show first 5 as examples"
   ],
   "id": "f496956d8744f611",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Found 13 station_ids in sessions_df that don't exist in stations_df\n",
      "['23ad8d0095', '956028aa4c', '00c4ca50ea', '162185ed79', '0dc8ed1cc1']\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T01:21:45.108958Z",
     "start_time": "2025-04-21T01:21:45.050625Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Merge to analyze the relationship\n",
    "merged_df = sessions_df.merge(stations_df[['station_id', 'port_no']],\n",
    "                             on='station_id',\n",
    "                             suffixes=('_session', '_station'))\n",
    "\n",
    "# Check if session port numbers are within the valid range for each station\n",
    "merged_df['valid_port'] = (merged_df['port_no_session'] >= 1) & (merged_df['port_no_session'] <= merged_df['port_no_station'])\n",
    "invalid_ports = sum(~merged_df['valid_port'])\n",
    "\n",
    "if invalid_ports == 0:\n",
    "    print(\"PASSED: All port numbers in sessions are within valid range for their stations\")\n",
    "else:\n",
    "    print(f\"WARNING: Found {invalid_ports} sessions using invalid port numbers\")\n",
    "\n",
    "# Show distribution of ports per station\n",
    "print(\"\\nDistribution of port_no in stations_df:\")\n",
    "print(stations_df['port_no'].value_counts().sort_index())\n",
    "\n",
    "# Show distribution of which ports are used in sessions\n",
    "print(\"\\nDistribution of port_no in sessions_df:\")\n",
    "print(sessions_df['port_no'].value_counts().sort_index())"
   ],
   "id": "5c22bd4a9cd1ee18",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Found 13745 sessions using invalid port numbers\n",
      "\n",
      "Distribution of port_no in stations_df:\n",
      "port_no\n",
      "1    19\n",
      "2    19\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Distribution of port_no in sessions_df:\n",
      "port_no\n",
      "1    34578\n",
      "2    31431\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T01:26:09.138601Z",
     "start_time": "2025-04-21T01:26:09.093089Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Test 1: Check if (station_id, port_no) is unique\n",
    "compound_key_duplicates = stations_df.duplicated(subset=['station_id', 'port_no']).sum()\n",
    "print(f\"Duplicated (station_id, port_no) pairs: {compound_key_duplicates}\")\n",
    "\n",
    "# Test 2: Analyze station_id counts\n",
    "station_counts = stations_df['station_id'].value_counts()\n",
    "print(\"\\nDistribution of station_id occurrences:\")\n",
    "print(station_counts.value_counts())  # How many stations appear once, twice, etc.\n",
    "\n",
    "# Test 3: Check port distribution per station\n",
    "port_distribution = stations_df.groupby('station_id')['port_no'].apply(list)\n",
    "print(\"\\nSample of port numbers per station:\")\n",
    "print(port_distribution.head())\n",
    "\n",
    "# Test 4: Verify all stations have expected port patterns\n",
    "stations_with_ports_1_and_2 = sum([(set(ports) == {1, 2}) for ports in port_distribution])\n",
    "print(f\"\\nStations with exactly ports 1 and 2: {stations_with_ports_1_and_2}\")\n",
    "print(f\"Total unique stations: {len(port_distribution)}\")\n",
    "\n",
    "# Test 5: Analyze the missing station references\n",
    "print(\"\\nExamining orphaned sessions:\")\n",
    "orphaned_sessions = sessions_df[~sessions_df['station_id'].isin(stations_df['station_id'])]\n",
    "print(f\"Number of orphaned sessions: {len(orphaned_sessions)}\")\n",
    "print(f\"Unique orphaned station IDs: {orphaned_sessions['station_id'].nunique()}\")\n",
    "\n",
    "# Test 6: Check port numbers in orphaned sessions\n",
    "print(\"\\nPort numbers used in orphaned sessions:\")\n",
    "print(orphaned_sessions['port_no'].value_counts())"
   ],
   "id": "60c287c0d49afd65",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicated (station_id, port_no) pairs: 0\n",
      "\n",
      "Distribution of station_id occurrences:\n",
      "count\n",
      "2    19\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample of port numbers per station:\n",
      "station_id\n",
      "0342d90fcf    [1, 2]\n",
      "047effd886    [1, 2]\n",
      "0b22b7c266    [1, 2]\n",
      "18173fd803    [1, 2]\n",
      "1ff7182ea0    [1, 2]\n",
      "Name: port_no, dtype: object\n",
      "\n",
      "Stations with exactly ports 1 and 2: 19\n",
      "Total unique stations: 19\n",
      "\n",
      "Examining orphaned sessions:\n",
      "Number of orphaned sessions: 36974\n",
      "Unique orphaned station IDs: 13\n",
      "\n",
      "Port numbers used in orphaned sessions:\n",
      "port_no\n",
      "1    19288\n",
      "2    17686\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T01:40:49.439058Z",
     "start_time": "2025-04-21T01:40:49.395785Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Identify orphaned sessions\n",
    "orphaned_sessions = sessions_df[~sessions_df['station_id'].isin(stations_df['station_id'])]\n",
    "\n",
    "# Get unique station_id and port_no combinations\n",
    "orphaned_pairs = orphaned_sessions[['station_id', 'port_no']].drop_duplicates()\n",
    "\n",
    "# Count sessions per combination\n",
    "pair_counts = orphaned_sessions.groupby(['station_id', 'port_no']).size().reset_index(name='session_count')\n",
    "\n",
    "# Sort by station_id and port_no for readability\n",
    "pair_counts = pair_counts.sort_values(['station_id', 'port_no'])\n",
    "\n",
    "print(f\"Total unique (station_id, port_no) pairs: {len(pair_counts)}\")\n",
    "print(\"\\nOrphaned station-port combinations with session counts:\")\n",
    "print(pair_counts)"
   ],
   "id": "cd8ddbec969f05ad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique (station_id, port_no) pairs: 26\n",
      "\n",
      "Orphaned station-port combinations with session counts:\n",
      "    station_id  port_no  session_count\n",
      "0   00c4ca50ea        1             75\n",
      "1   00c4ca50ea        2             69\n",
      "2   01335ad401        1            134\n",
      "3   01335ad401        2             77\n",
      "4   0dc8ed1cc1        1           6557\n",
      "..         ...      ...            ...\n",
      "21  a9571abfa4        2            106\n",
      "22  a96c3b900c        1             76\n",
      "23  a96c3b900c        2             86\n",
      "24  bba10a9daf        1           1716\n",
      "25  bba10a9daf        2           1748\n",
      "\n",
      "[26 rows x 3 columns]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T01:42:47.357405Z",
     "start_time": "2025-04-21T01:42:47.314295Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orphaned stations with address information: 13 out of 13\n",
      "\n",
      "Station IDs with their addresses:\n",
      "    station_id                                            address\n",
      "0   00c4ca50ea  8888 University Dr W, Floor P7000, Burnaby, Br...\n",
      "1   01335ad401  8888 University Dr W, Burnaby, British Columbi...\n",
      "2   0dc8ed1cc1  8915 Cornerstone Mews, Burnaby, British Columb...\n",
      "3   162185ed79  8999 Nelson Way, Burnaby, British Columbia, V5...\n",
      "4   18db03c780  8888 University Dr W, Burnaby, British Columbi...\n",
      "5   23ad8d0095  8888 University  Drive, Burnaby, British Colum...\n",
      "6   4ce863e612  8888 University Dr W, Burnaby, British Columbi...\n",
      "7   615db15a48  13419 103 Ave Floor, Surrey, British Columbia,...\n",
      "8   87adf1b6d0  13419 103 Ave, Floor P1, Surrey, British Colum...\n",
      "9   956028aa4c  8888 University Dr W, Floor P7000, Burnaby, Br...\n",
      "10  a9571abfa4  8888 University Dr W, Floor P7000, Burnaby, Br...\n",
      "11  a96c3b900c  8888 University Dr W, Floor P7000, Burnaby, Br...\n",
      "12  bba10a9daf  8999 Nelson Way, Burnaby, British Columbia, V5...\n",
      "\n",
      "Stations with multiple addresses: 5\n",
      "Stations with inconsistent addresses:\n",
      "['0dc8ed1cc1', '162185ed79', '23ad8d0095', '615db15a48', '87adf1b6d0']\n"
     ]
    }
   ],
   "execution_count": 9,
   "source": [
    "# Get the orphaned sessions\n",
    "orphaned_sessions = sessions_df[~sessions_df['station_id'].isin(stations_df['station_id'])]\n",
    "\n",
    "# Group by station_id and check for addresses\n",
    "station_addresses = orphaned_sessions.groupby('station_id')['address'].first().reset_index()\n",
    "\n",
    "# Check if all orphaned stations have address information\n",
    "missing_addresses = station_addresses['address'].isnull().sum()\n",
    "\n",
    "print(f\"Orphaned stations with address information: {len(station_addresses) - missing_addresses} out of {len(station_addresses)}\")\n",
    "print(\"\\nStation IDs with their addresses:\")\n",
    "print(station_addresses)\n",
    "\n",
    "# Check if each station has consistent address information\n",
    "address_consistency = orphaned_sessions.groupby('station_id')['address'].nunique().reset_index()\n",
    "address_consistency.columns = ['station_id', 'unique_address_count']\n",
    "inconsistent_stations = address_consistency[address_consistency['unique_address_count'] > 1]\n",
    "\n",
    "print(f\"\\nStations with multiple addresses: {len(inconsistent_stations)}\")\n",
    "if len(inconsistent_stations) > 0:\n",
    "    print(\"Stations with inconsistent addresses:\")\n",
    "    print(inconsistent_stations['station_id'].tolist())"
   ],
   "id": "4e1d9fb5ed324c65"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T01:43:57.265005Z",
     "start_time": "2025-04-21T01:43:57.218157Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# List of stations with inconsistent addresses\n",
    "inconsistent_station_ids = ['0dc8ed1cc1', '162185ed79', '23ad8d0095', '615db15a48', '87adf1b6d0']\n",
    "\n",
    "# For each inconsistent station, get all unique addresses\n",
    "for station_id in inconsistent_station_ids:\n",
    "    # Filter sessions for this station\n",
    "    station_sessions = orphaned_sessions[orphaned_sessions['station_id'] == station_id]\n",
    "\n",
    "    # Get unique addresses\n",
    "    unique_addresses = station_sessions['address'].unique()\n",
    "\n",
    "    print(f\"\\nStation ID: {station_id}\")\n",
    "    print(f\"Number of unique addresses: {len(unique_addresses)}\")\n",
    "    print(\"Unique addresses:\")\n",
    "    for i, address in enumerate(unique_addresses, 1):\n",
    "        print(f\"{i}. {address}\")"
   ],
   "id": "773938304c8b55d9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Station ID: 0dc8ed1cc1\n",
      "Number of unique addresses: 2\n",
      "Unique addresses:\n",
      "1. 8915 Cornerstone Mews, Burnaby, British Columbia, V5A 4Y6, Canada\n",
      "2. 8911 Cornerstone Mews, Burnaby, British Columbia, V5A 4Y6, Canada\n",
      "\n",
      "Station ID: 162185ed79\n",
      "Number of unique addresses: 2\n",
      "Unique addresses:\n",
      "1. 8999 Nelson Way, Burnaby, British Columbia, V5G 4N2, Canada\n",
      "2. 8999 Nelson Way, Burnaby, British Columbia, V5A 4W9, Canada\n",
      "\n",
      "Station ID: 23ad8d0095\n",
      "Number of unique addresses: 2\n",
      "Unique addresses:\n",
      "1. 8888 University  Drive, Burnaby, British Columbia, V5A1S6, Canada\n",
      "2. 8888 University Dr, Burnaby, British Columbia, V5A 1S6, Canada\n",
      "\n",
      "Station ID: 615db15a48\n",
      "Number of unique addresses: 2\n",
      "Unique addresses:\n",
      "1. 13419 103 Ave Floor, Surrey, British Columbia, V3T 1S6, Canada\n",
      "2. 13419 103 Ave, Surrey, British Columbia, V3T 1S6, Canada\n",
      "\n",
      "Station ID: 87adf1b6d0\n",
      "Number of unique addresses: 2\n",
      "Unique addresses:\n",
      "1. 13419 103 Ave, Floor P1, Surrey, British Columbia, V3T 1R7, Canada\n",
      "2. 13419 103 Ave, Surrey, British Columbia, V3T 1R7, Canada\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T02:06:40.290651Z",
     "start_time": "2025-04-21T02:06:40.223694Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a dataframe for the missing stations\n",
    "new_stations_data = []\n",
    "\n",
    "# New station information\n",
    "station_info = [\n",
    "    {\"station_id\": \"0dc8ed1cc1\", \"address\": \"8915 Cornerstone Mews, Burnaby, British Columbia, V5A 4Y6, Canada\", \"location_lat\": 49.27806955715426, \"location_long\": -122.91203807404098},\n",
    "    {\"station_id\": \"162185ed79\", \"address\": \"8999 Nelson Way, Burnaby, British Columbia, V5G 4N2, Canada\", \"location_lat\": 49.27380817107044, \"location_long\": -122.9122931912351},\n",
    "    {\"station_id\": \"23ad8d0095\", \"address\": \"8888 University Drive, Burnaby, British Columbia, V5A1S6, Canada\", \"location_lat\": 49.2797337375215, \"location_long\": -122.92418284890641},\n",
    "    {\"station_id\": \"615db15a48\", \"address\": \"13419 103 Ave, Surrey, British Columbia, V3T 1S6, Canada\", \"location_lat\": 49.190413065036694, \"location_long\": -122.85111038200404},\n",
    "    {\"station_id\": \"87adf1b6d0\", \"address\": \"13419 103 Ave, Floor P1, Surrey, British Columbia, V3T 1R7, Canada\", \"location_lat\": 49.19048327828886, \"location_long\": -122.85091700288174},\n",
    "    {\"station_id\": \"00c4ca50ea\", \"address\": \"8888 University Dr W, Floor P7000, Burnaby, British Columbia, Canada\", \"location_lat\": 49.27963567579469, \"location_long\": -122.92405411918756},\n",
    "    {\"station_id\": \"01335ad401\", \"address\": \"8888 University Dr W, Burnaby, British Columbia, Canada\", \"location_lat\": 49.27963567579469, \"location_long\": -122.92405411918756},\n",
    "    {\"station_id\": \"18db03c780\", \"address\": \"8888 University Dr W, Burnaby, British Columbia, Canada\", \"location_lat\": 49.27963567579469, \"location_long\": -122.92405411918756},\n",
    "    {\"station_id\": \"4ce863e612\", \"address\": \"8888 University Dr W, Burnaby, British Columbia, Canada\", \"location_lat\": 49.27963567579469, \"location_long\": -122.92405411918756},\n",
    "    {\"station_id\": \"956028aa4c\", \"address\": \"8888 University Dr W, Floor P7000, Burnaby, British Columbia, Canada\", \"location_lat\": 49.27963567579469, \"location_long\": -122.92405411918756},\n",
    "    {\"station_id\": \"a9571abfa4\", \"address\": \"8888 University Dr W, Floor P7000, Burnaby, British Columbia, Canada\", \"location_lat\": 49.27963567579469, \"location_long\": -122.92405411918756},\n",
    "    {\"station_id\": \"a96c3b900c\", \"address\": \"8888 University Dr W, Floor P7000, Burnaby, British Columbia, Canada\", \"location_lat\": 49.27963567579469, \"location_long\": -122.92405411918756},\n",
    "    {\"station_id\": \"bba10a9daf\", \"address\": \"8999 Nelson Way, Burnaby, British Columbia, V5A 4W9, Canada\", \"location_lat\": 49.27380817107044, \"location_long\": -122.91220736054855}\n",
    "]\n",
    "\n",
    "# Create a DataFrame with just the columns we're filling\n",
    "for station in station_info:\n",
    "    for port in [1, 2]:\n",
    "        row = {\n",
    "            'station_id': station['station_id'],\n",
    "            'port_no': port,\n",
    "            'address': station['address'],\n",
    "            'location_lat': station['location_lat'],\n",
    "            'location_long': station['location_long'],\n",
    "            'reservable': 0\n",
    "        }\n",
    "        new_stations_data.append(row)\n",
    "\n",
    "# Create a dataframe with the new stations\n",
    "new_stations_df = pd.DataFrame(new_stations_data)\n",
    "\n",
    "# Get integer column names from original dataframe\n",
    "int_columns = stations_df.select_dtypes(include=['int64']).columns.tolist()\n",
    "\n",
    "# For other columns that need non-null values, use appropriate defaults\n",
    "for col in stations_df.columns:\n",
    "    if col not in new_stations_df.columns:\n",
    "        if col in int_columns:\n",
    "            # For integer columns, use 0 as default\n",
    "            new_stations_df[col] = 0\n",
    "        else:\n",
    "            # For other columns, use empty string for object types\n",
    "            if stations_df[col].dtype == 'object':\n",
    "                new_stations_df[col] = ''\n",
    "\n",
    "# Combine with the original stations dataframe\n",
    "stations_df = pd.concat([stations_df, new_stations_df], ignore_index=True)\n",
    "\n",
    "print(f\"Combined stations count: {len(stations_df)}\")"
   ],
   "id": "673d7fc812799c92",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined stations count: 64\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T04:30:06.041366Z",
     "start_time": "2025-04-21T04:30:05.718672Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Ensure date columns are in datetime format\n",
    "if not pd.api.types.is_datetime64_dtype(sessions_df['start_dt']):\n",
    "    sessions_df['start_dt'] = pd.to_datetime(sessions_df['start_dt'])\n",
    "\n",
    "if not pd.api.types.is_datetime64_dtype(sessions_df['end_dt']):\n",
    "    sessions_df['end_dt'] = pd.to_datetime(sessions_df['end_dt'])\n",
    "\n",
    "# Get the min and max dates\n",
    "min_date = sessions_df['start_dt'].min()\n",
    "max_date = sessions_df['end_dt'].max()\n",
    "\n",
    "# Calculate the duration of the dataset\n",
    "date_range_days = (max_date - min_date).days\n",
    "\n",
    "print(f\"Dataset spans from {min_date.date()} to {max_date.date()}\")\n",
    "print(f\"Total time period: {date_range_days} days ({date_range_days/30.44:.1f} months)\")\n",
    "\n",
    "# Count sessions by month to check distribution\n",
    "sessions_df['year_month'] = sessions_df['start_dt'].dt.to_period('M')\n",
    "monthly_counts = sessions_df['year_month'].value_counts().sort_index()\n",
    "\n",
    "print(\"\\nSessions per month:\")\n",
    "print(monthly_counts)"
   ],
   "id": "45e82827bfd3f78",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset spans from 2019-11-06 to 2025-04-17\n",
      "Total time period: 1989 days (65.3 months)\n",
      "\n",
      "Sessions per month:\n",
      "year_month\n",
      "2019-11     479\n",
      "2019-12     538\n",
      "2020-01     622\n",
      "2020-02     646\n",
      "2020-03     627\n",
      "           ... \n",
      "2024-12    1663\n",
      "2025-01    2015\n",
      "2025-02    1874\n",
      "2025-03    2072\n",
      "2025-04    1218\n",
      "Freq: M, Name: count, Length: 66, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 15
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
